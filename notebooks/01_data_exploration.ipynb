{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Object Detection - Data Exploration\n",
    "\n",
    "This notebook provides tools for exploring and analyzing traffic object detection datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from datasets import TrafficDataset, get_transforms\n",
    "from utils.data_utils import verify_dataset, create_class_mapping\n",
    "from utils.visualization import plot_class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "DATASET_ROOT = \"../data/traffic\"\n",
    "TRAIN_ANNOTATIONS = os.path.join(DATASET_ROOT, \"train_annotations.json\")\n",
    "VAL_ANNOTATIONS = os.path.join(DATASET_ROOT, \"val_annotations.json\")\n",
    "TEST_ANNOTATIONS = os.path.join(DATASET_ROOT, \"test_annotations.json\")\n",
    "IMAGES_DIR = os.path.join(DATASET_ROOT, \"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Analyze Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations\n",
    "def load_annotations(ann_file):\n",
    "    with open(ann_file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Check which annotation files exist\n",
    "splits = {}\n",
    "for split_name, ann_file in [(\"train\", TRAIN_ANNOTATIONS), (\"val\", VAL_ANNOTATIONS), (\"test\", TEST_ANNOTATIONS)]:\n",
    "    if os.path.exists(ann_file):\n",
    "        splits[split_name] = load_annotations(ann_file)\n",
    "        print(f\"{split_name.capitalize()} split: {len(splits[split_name])} images\")\n",
    "    else:\n",
    "        print(f\"{split_name.capitalize()} annotations not found: {ann_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_split(data, split_name):\n",
    "    total_images = len(data)\n",
    "    total_objects = sum(len(img_data['objects']) for img_data in data.values())\n",
    "    empty_images = sum(1 for img_data in data.values() if len(img_data['objects']) == 0)\n",
    "    \n",
    "    # Class distribution\n",
    "    class_counts = Counter()\n",
    "    for img_data in data.values():\n",
    "        for obj in img_data['objects']:\n",
    "            class_counts[obj['class']] += 1\n",
    "    \n",
    "    print(f\"\\n{split_name.upper()} SPLIT STATISTICS:\")\n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"Total objects: {total_objects}\")\n",
    "    print(f\"Empty images: {empty_images} ({empty_images/total_images*100:.1f}%)\")\n",
    "    print(f\"Avg objects per image: {total_objects/total_images:.2f}\")\n",
    "    print(f\"Classes found: {len(class_counts)}\")\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Analyze each split\n",
    "split_stats = {}\n",
    "for split_name, data in splits.items():\n",
    "    split_stats[split_name] = analyze_split(data, split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution for each split\n",
    "for split_name, class_counts in split_stats.items():\n",
    "    if class_counts:\n",
    "        fig = plot_class_distribution(dict(class_counts), top_n=15)\n",
    "        plt.title(f'Class Distribution - {split_name.upper()} Split')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Images Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(data, images_dir, num_samples=6):\n",
    "    \"\"\"\n",
    "    Visualize sample images with their annotations.\n",
    "    \"\"\"\n",
    "    import matplotlib.patches as patches\n",
    "    import random\n",
    "    \n",
    "    # Get random samples\n",
    "    sample_ids = random.sample(list(data.keys()), min(num_samples, len(data)))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, 10))\n",
    "    \n",
    "    for i, img_id in enumerate(sample_ids):\n",
    "        img_data = data[img_id]\n",
    "        img_path = os.path.join(images_dir, img_data['filename'])\n",
    "        \n",
    "        if os.path.exists(img_path):\n",
    "            # Load and display image\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Image: {img_data['filename']}\\nObjects: {len(img_data['objects'])}\")\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "            # Draw bounding boxes\n",
    "            for obj in img_data['objects']:\n",
    "                bbox = obj['bbox']  # [x, y, w, h]\n",
    "                x, y, w, h = bbox\n",
    "                \n",
    "                # Choose color based on class\n",
    "                color = colors[hash(obj['class']) % len(colors)]\n",
    "                \n",
    "                # Draw rectangle\n",
    "                rect = patches.Rectangle(\n",
    "                    (x, y), w, h,\n",
    "                    linewidth=2, edgecolor=color, facecolor='none'\n",
    "                )\n",
    "                axes[i].add_patch(rect)\n",
    "                \n",
    "                # Add label\n",
    "                axes[i].text(\n",
    "                    x, y-5, obj['class'],\n",
    "                    fontsize=8, color='white',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.7)\n",
    "                )\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f\"Image not found:\\n{img_path}\", \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from each split\n",
    "for split_name, data in splits.items():\n",
    "    print(f\"\\nSample images from {split_name} split:\")\n",
    "    visualize_sample_images(data, IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding Box Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bounding_boxes(data):\n",
    "    \"\"\"\n",
    "    Analyze bounding box sizes and aspect ratios.\n",
    "    \"\"\"\n",
    "    box_areas = []\n",
    "    box_widths = []\n",
    "    box_heights = []\n",
    "    aspect_ratios = []\n",
    "    \n",
    "    for img_data in data.values():\n",
    "        for obj in img_data['objects']:\n",
    "            bbox = obj['bbox']\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            box_areas.append(w * h)\n",
    "            box_widths.append(w)\n",
    "            box_heights.append(h)\n",
    "            \n",
    "            if h > 0:\n",
    "                aspect_ratios.append(w / h)\n",
    "    \n",
    "    return {\n",
    "        'areas': box_areas,\n",
    "        'widths': box_widths,\n",
    "        'heights': box_heights,\n",
    "        'aspect_ratios': aspect_ratios\n",
    "    }\n",
    "\n",
    "# Analyze bounding boxes for train split\n",
    "if 'train' in splits:\n",
    "    bbox_stats = analyze_bounding_boxes(splits['train'])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Box areas\n",
    "    axes[0, 0].hist(bbox_stats['areas'], bins=50, alpha=0.7)\n",
    "    axes[0, 0].set_title('Bounding Box Areas')\n",
    "    axes[0, 0].set_xlabel('Area (pixelsÂ²)')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    \n",
    "    # Box widths\n",
    "    axes[0, 1].hist(bbox_stats['widths'], bins=50, alpha=0.7)\n",
    "    axes[0, 1].set_title('Bounding Box Widths')\n",
    "    axes[0, 1].set_xlabel('Width (pixels)')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    \n",
    "    # Box heights\n",
    "    axes[1, 0].hist(bbox_stats['heights'], bins=50, alpha=0.7)\n",
    "    axes[1, 0].set_title('Bounding Box Heights')\n",
    "    axes[1, 0].set_xlabel('Height (pixels)')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    \n",
    "    # Aspect ratios\n",
    "    axes[1, 1].hist(bbox_stats['aspect_ratios'], bins=50, alpha=0.7)\n",
    "    axes[1, 1].set_title('Aspect Ratios (W/H)')\n",
    "    axes[1, 1].set_xlabel('Aspect Ratio')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Bounding Box Statistics:\")\n",
    "    print(f\"Area - Mean: {np.mean(bbox_stats['areas']):.1f}, Std: {np.std(bbox_stats['areas']):.1f}\")\n",
    "    print(f\"Width - Mean: {np.mean(bbox_stats['widths']):.1f}, Std: {np.std(bbox_stats['widths']):.1f}\")\n",
    "    print(f\"Height - Mean: {np.mean(bbox_stats['heights']):.1f}, Std: {np.std(bbox_stats['heights']):.1f}\")\n",
    "    print(f\"Aspect Ratio - Mean: {np.mean(bbox_stats['aspect_ratios']):.2f}, Std: {np.std(bbox_stats['aspect_ratios']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing images and other data quality issues\n",
    "def check_data_quality(data, images_dir):\n",
    "    issues = {\n",
    "        'missing_images': [],\n",
    "        'empty_annotations': [],\n",
    "        'invalid_bboxes': [],\n",
    "        'unknown_classes': []\n",
    "    }\n",
    "    \n",
    "    known_classes = {\n",
    "        'car', 'truck', 'bus', 'motorcycle', 'bicycle', \n",
    "        'person', 'traffic_light', 'traffic_sign', 'stop_sign'\n",
    "    }\n",
    "    \n",
    "    for img_id, img_data in data.items():\n",
    "        filename = img_data['filename']\n",
    "        img_path = os.path.join(images_dir, filename)\n",
    "        \n",
    "        # Check if image exists\n",
    "        if not os.path.exists(img_path):\n",
    "            issues['missing_images'].append(filename)\n",
    "        \n",
    "        # Check for empty annotations\n",
    "        if len(img_data['objects']) == 0:\n",
    "            issues['empty_annotations'].append(filename)\n",
    "        \n",
    "        # Check bounding boxes and classes\n",
    "        for obj in img_data['objects']:\n",
    "            bbox = obj['bbox']\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Check for invalid bounding boxes\n",
    "            if w <= 0 or h <= 0 or x < 0 or y < 0:\n",
    "                issues['invalid_bboxes'].append((filename, bbox))\n",
    "            \n",
    "            # Check for unknown classes\n",
    "            if obj['class'] not in known_classes:\n",
    "                issues['unknown_classes'].append((filename, obj['class']))\n",
    "    \n",
    "    return issues\n",
    "\n",
    "# Check data quality for each split\n",
    "for split_name, data in splits.items():\n",
    "    print(f\"\\nData Quality Check - {split_name.upper()} Split:\")\n",
    "    issues = check_data_quality(data, IMAGES_DIR)\n",
    "    \n",
    "    print(f\"Missing images: {len(issues['missing_images'])}\")\n",
    "    print(f\"Empty annotations: {len(issues['empty_annotations'])}\")\n",
    "    print(f\"Invalid bounding boxes: {len(issues['invalid_bboxes'])}\")\n",
    "    print(f\"Unknown classes: {len(issues['unknown_classes'])}\")\n",
    "    \n",
    "    if issues['missing_images']:\n",
    "        print(f\"  Sample missing images: {issues['missing_images'][:5]}\")\n",
    "    \n",
    "    if issues['unknown_classes']:\n",
    "        unknown_class_names = list(set([cls for _, cls in issues['unknown_classes']]))\n",
    "        print(f\"  Unknown classes found: {unknown_class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "total_images = sum(len(data) for data in splits.values())\n",
    "total_objects = sum(sum(len(img_data['objects']) for img_data in data.values()) for data in splits.values())\n",
    "\n",
    "print(f\"Total images across all splits: {total_images}\")\n",
    "print(f\"Total objects across all splits: {total_objects}\")\n",
    "\n",
    "# Combined class distribution\n",
    "all_classes = Counter()\n",
    "for split_stats_dict in split_stats.values():\n",
    "    all_classes.update(split_stats_dict)\n",
    "\n",
    "print(f\"\\nClass distribution across all splits:\")\n",
    "for class_name, count in all_classes.most_common():\n",
    "    percentage = count / total_objects * 100\n",
    "    print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDataset is ready for training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}